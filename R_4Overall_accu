# overall-accuracy.R

## Lecture notes

library(dslabs)
library(dplyr)

data(heights)

## Define predictor 'x' and outcome 'y'
y <- heights$sex
x <- heights$height

## Create training and test sets
set.seed(2)
test_index <-
  caret::createDataPartition(y, times = 1, p = 0.5, list = FALSE)
train_set <- heights[-test_index, ]
test_set <- heights[test_index, ]

## Guessing the outcome
y_hat <- sample(c("Male", "Female"), length(test_index), replace = TRUE) %>% 
  factor(levels = levels(test_set$sex))

## Overall accuracy is defined as the overall proportion that is 
## predicted correctly.
mean(y_hat == test_set$sex) 

## Now, to go beyond mere guessing
heights %>% 
  group_by(sex) %>% 
  summarise(mean(height), sd(height))

## Predict Male when height is within 2 standard deviations for the Males
y_hat <- ifelse(x > 62, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))
mean(y_hat == test_set$sex) 

## Now, we get the best value by examining accuracy for different cutoffs
cutoff <- seq(61, 70)
accuracy <- purrr::map_dbl(cutoff, function(x) {
  y_hat <- ifelse(train_set$height > x, "Male", "Female") %>% 
    factor(levels = levels(test_set$sex))
  mean(y_hat == train_set$sex)
})

qplot(cutoff, accuracy, geom = c("point", "line"))
max(accuracy)
(best_cutoff <- cutoff[which.max(accuracy)])

## Test cutoff on test set
y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))
y_hat <- factor(y_hat)
mean(y_hat == test_set$sex)
@Joycesongyang
